# Conversational AI Website Builder with Groq + OpenRouter + MCP

## üéØ Architecture Overview

This guide implements a **conversational AI website builder** where:

1. **Groq** handles natural conversation and intelligent tool selection
2. **OpenRouter** executes specific tasks with specialized models
3. **MCP Tools** provide the underlying functionality
4. **User** gets a ChatGPT-like experience with reasoning and explanations

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User: "Build me a blog website with authentication"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend (React)                                         ‚îÇ
‚îÇ - Chat Interface                                         ‚îÇ
‚îÇ - Message streaming                                      ‚îÇ
‚îÇ - Real-time updates                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì WebSocket/HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Backend API                                              ‚îÇ
‚îÇ - Receives user messages                                 ‚îÇ
‚îÇ - Manages conversation state                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Groq LLM (llama-3.3-70b-versatile)                      ‚îÇ
‚îÇ - Understands user intent                                ‚îÇ
‚îÇ - Provides natural conversation                          ‚îÇ
‚îÇ - Decides which tools to use                             ‚îÇ
‚îÇ - Explains reasoning                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì Tool Selection
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tool Router                                              ‚îÇ
‚îÇ - Routes to appropriate MCP tool                         ‚îÇ
‚îÇ - Selects OpenRouter model for task                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MCP Tools + OpenRouter Models                           ‚îÇ
‚îÇ ‚îú‚îÄ Research ‚Üí Perplexity Sonar                          ‚îÇ
‚îÇ ‚îú‚îÄ PRD Generation ‚Üí Claude 3.5 Sonnet                   ‚îÇ
‚îÇ ‚îú‚îÄ User Stories ‚Üí Claude 3.5 Sonnet                     ‚îÇ
‚îÇ ‚îú‚îÄ Task Lists ‚Üí Gemini 2.5 Flash                        ‚îÇ
‚îÇ ‚îî‚îÄ Code Generation ‚Üí Gemini 2.5 Flash or GPT-4          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Response back to Groq                                    ‚îÇ
‚îÇ - Groq interprets results                                ‚îÇ
‚îÇ - Generates natural response                             ‚îÇ
‚îÇ - Streams back to user                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîë API Keys Required

### 1. **Groq API Key** (Free - Fast inference)
- Sign up: https://console.groq.com/
- Get API key from dashboard
- Free tier: Very generous limits

### 2. **OpenRouter API Key** (Pay per use)
- Sign up: https://openrouter.ai/
- Get API key
- Add credits ($10 recommended to start)

---

## üì¶ Installation

### Backend Dependencies

```bash
cd backend
npm install express cors dotenv groq-sdk vibe-coder-mcp axios ws
```

---

## üèóÔ∏è Backend Implementation

### Step 1: Environment Configuration

Create `backend/.env`:

```env
# Server Configuration
PORT=3000
NODE_ENV=development

# Groq Configuration (Conversational AI)
GROQ_API_KEY=gsk_your_groq_api_key_here

# OpenRouter Configuration (Tool Execution)
OPENROUTER_API_KEY=sk-or-v1-your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# MCP Configuration
VIBE_PROJECT_ROOT=../generated-projects
VIBE_CODER_OUTPUT_DIR=../generated-projects/VibeCoderOutput

# Model Selection for Each Tool
RESEARCH_MODEL=perplexity/sonar-pro
PRD_MODEL=anthropic/claude-3.5-sonnet
USER_STORIES_MODEL=anthropic/claude-3.5-sonnet
TASK_LIST_MODEL=google/gemini-2.5-flash-preview-05-20
CODE_GENERATION_MODEL=google/gemini-2.5-flash-preview-05-20
# Alternative: CODE_GENERATION_MODEL=openai/gpt-4-turbo-preview

# Groq Model
GROQ_MODEL=llama-3.3-70b-versatile

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:3000

# Logging
LOG_LEVEL=info
```

---

### Step 2: Create Groq Conversation Service

Create `backend/services/groqService.js`:

```javascript
import Groq from 'groq-sdk';

class GroqService {
  constructor() {
    this.client = new Groq({
      apiKey: process.env.GROQ_API_KEY
    });
    this.model = process.env.GROQ_MODEL || 'llama-3.3-70b-versatile';
    
    // Define available tools for Groq to use
    this.tools = [
      {
        type: 'function',
        function: {
          name: 'research_best_practices',
          description: 'Research best practices, latest trends, and technologies for a given topic or project type. Use this when user asks about technologies, frameworks, or needs recommendations.',
          parameters: {
            type: 'object',
            properties: {
              query: {
                type: 'string',
                description: 'The research query, e.g., "best practices for building a blog platform with React"'
              }
            },
            required: ['query']
          }
        }
      },
      {
        type: 'function',
        function: {
          name: 'generate_prd',
          description: 'Generate a comprehensive Product Requirements Document (PRD) for a software project. Use this when you have a clear understanding of what the user wants to build.',
          parameters: {
            type: 'object',
            properties: {
              productDescription: {
                type: 'string',
                description: 'Detailed description of the product to build'
              }
            },
            required: ['productDescription']
          }
        }
      },
      {
        type: 'function',
        function: {
          name: 'generate_user_stories',
          description: 'Generate detailed user stories with acceptance criteria from a PRD. Use this after creating a PRD to break it down into user-focused features.',
          parameters: {
            type: 'object',
            properties: {
              prdContent: {
                type: 'string',
                description: 'The PRD content to generate user stories from'
              }
            },
            required: ['prdContent']
          }
        }
      },
      {
        type: 'function',
        function: {
          name: 'generate_task_list',
          description: 'Generate a detailed development task list from user stories. Use this to break down user stories into actionable development tasks.',
          parameters: {
            type: 'object',
            properties: {
              userStoriesContent: {
                type: 'string',
                description: 'The user stories content to generate tasks from'
              }
            },
            required: ['userStoriesContent']
          }
        }
      },
      {
        type: 'function',
        function: {
          name: 'generate_website_code',
          description: 'Generate complete full-stack website code (frontend + backend). Use this as the final step after planning is complete.',
          parameters: {
            type: 'object',
            properties: {
              productDescription: {
                type: 'string',
                description: 'Complete description of the website to generate'
              },
              frontend: {
                type: 'string',
                enum: ['react', 'vue', 'angular', 'svelte'],
                description: 'Frontend framework to use'
              },
              backend: {
                type: 'string',
                enum: ['nodejs', 'python', 'go', 'java'],
                description: 'Backend technology to use'
              }
            },
            required: ['productDescription', 'frontend', 'backend']
          }
        }
      }
    ];
  }

  /**
   * Create a chat completion with tool calling
   */
  async chat(messages, tools = this.tools) {
    try {
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: messages,
        tools: tools,
        tool_choice: 'auto',
        temperature: 0.7,
        max_tokens: 2048
      });

      return response;
    } catch (error) {
      console.error('Groq API Error:', error);
      throw error;
    }
  }

  /**
   * Stream chat completion
   */
  async streamChat(messages, tools = this.tools) {
    try {
      const stream = await this.client.chat.completions.create({
        model: this.model,
        messages: messages,
        tools: tools,
        tool_choice: 'auto',
        temperature: 0.7,
        max_tokens: 2048,
        stream: true
      });

      return stream;
    } catch (error) {
      console.error('Groq Stream Error:', error);
      throw error;
    }
  }

  /**
   * Generate system prompt for website builder
   */
  getSystemPrompt() {
    return {
      role: 'system',
      content: `You are an expert AI website builder assistant. Your role is to help users create websites through natural conversation.

PERSONALITY:
- Friendly, enthusiastic, and encouraging
- Use conversational language, not technical jargon
- Show genuine excitement about helping build their project
- Be patient and ask clarifying questions when needed

WORKFLOW:
1. **Understand Requirements**: Ask questions to fully understand what the user wants
2. **Research**: Use research_best_practices to find the best approaches
3. **Plan**: Generate PRD and user stories for structured planning
4. **Build**: Generate the actual website code
5. **Explain**: Always explain your choices and reasoning

TOOL USAGE:
- Use tools step-by-step, explaining what you're doing
- Don't rush - ensure you understand requirements before generating code
- After using a tool, summarize the results in natural language

CONVERSATION STYLE:
- "Great idea! Let me think about the best way to build this..."
- "I'm researching modern approaches for this type of website..."
- "Based on what I found, I recommend using React because..."
- "Your website is taking shape! Here's what I'm creating..."

IMPORTANT:
- Always explain WHY you're making specific technical choices
- Break down complex concepts into simple terms
- Be proactive in suggesting features they might not have thought of
- Celebrate progress and completed milestones`
    };
  }
}

export default new GroqService();
```

---

### Step 3: Enhanced MCP Service with Model Selection

Update `backend/services/mcpService.js`:

```javascript
import { spawn } from 'child_process';
import path from 'path';
import { fileURLToPath } from 'url';
import axios from 'axios';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

class MCPService {
  constructor() {
    this.mcpProcess = null;
    this.mcpBaseUrl = 'http://localhost:3001';
    this.isReady = false;
    
    // Model configuration for each tool
    this.modelConfig = {
      research: process.env.RESEARCH_MODEL || 'perplexity/sonar-pro',
      prd: process.env.PRD_MODEL || 'anthropic/claude-3.5-sonnet',
      userStories: process.env.USER_STORIES_MODEL || 'anthropic/claude-3.5-sonnet',
      taskList: process.env.TASK_LIST_MODEL || 'google/gemini-2.5-flash-preview-05-20',
      codeGeneration: process.env.CODE_GENERATION_MODEL || 'google/gemini-2.5-flash-preview-05-20'
    };
  }

  async startServer() {
    if (this.mcpProcess) {
      console.log('MCP Server already running');
      return;
    }

    console.log('üöÄ Starting MCP Server with OpenRouter...');
    console.log('üìä Model Configuration:');
    console.log(`   Research: ${this.modelConfig.research}`);
    console.log(`   PRD: ${this.modelConfig.prd}`);
    console.log(`   User Stories: ${this.modelConfig.userStories}`);
    console.log(`   Task List: ${this.modelConfig.taskList}`);
    console.log(`   Code Gen: ${this.modelConfig.codeGeneration}`);

    this.mcpProcess = spawn('npx', ['vibe-coder-mcp', '--sse'], {
      env: {
        ...process.env,
        OPENROUTER_API_KEY: process.env.OPENROUTER_API_KEY,
        VIBE_PROJECT_ROOT: path.resolve(__dirname, process.env.VIBE_PROJECT_ROOT),
        VIBE_CODER_OUTPUT_DIR: path.resolve(__dirname, process.env.VIBE_CODER_OUTPUT_DIR),
        // Pass model configuration to MCP
        GEMINI_MODEL: this.modelConfig.codeGeneration,
        LOG_LEVEL: process.env.LOG_LEVEL || 'info',
      },
      stdio: ['ignore', 'pipe', 'pipe']
    });

    this.mcpProcess.stdout.on('data', (data) => {
      console.log(`[MCP] ${data.toString().trim()}`);
      if (data.toString().includes('Server started')) {
        this.isReady = true;
      }
    });

    this.mcpProcess.stderr.on('data', (data) => {
      console.error(`[MCP Error] ${data.toString().trim()}`);
    });

    this.mcpProcess.on('close', (code) => {
      console.log(`MCP Server exited with code ${code}`);
      this.mcpProcess = null;
      this.isReady = false;
    });

    await this.waitForReady();
  }

  async waitForReady(timeout = 30000) {
    const startTime = Date.now();
    while (!this.isReady && Date.now() - startTime < timeout) {
      await new Promise(resolve => setTimeout(resolve, 500));
    }
    if (!this.isReady) {
      throw new Error('MCP Server failed to start within timeout');
    }
    console.log('‚úÖ MCP Server is ready!');
  }

  stopServer() {
    if (this.mcpProcess) {
      this.mcpProcess.kill();
      this.mcpProcess = null;
      this.isReady = false;
      console.log('MCP Server stopped');
    }
  }

  async executeTool(toolName, params) {
    if (!this.isReady) {
      throw new Error('MCP Server is not ready');
    }

    try {
      console.log(`[MCP] Executing tool: ${toolName}`);
      const response = await axios.post(`${this.mcpBaseUrl}/mcp/execute`, {
        tool: toolName,
        arguments: params
      }, {
        timeout: 120000
      });

      return response.data;
    } catch (error) {
      console.error(`Error executing MCP tool ${toolName}:`, error.message);
      throw error;
    }
  }

  /**
   * Research with Perplexity Sonar
   */
  async research(query) {
    console.log(`[OpenRouter:${this.modelConfig.research}] Researching: ${query}`);
    return await this.executeTool('research', { query });
  }

  /**
   * Generate PRD with Claude 3.5 Sonnet
   */
  async generatePRD(productDescription) {
    console.log(`[OpenRouter:${this.modelConfig.prd}] Generating PRD`);
    return await this.executeTool('prd-generator', { productDescription });
  }

  /**
   * Generate User Stories with Claude 3.5 Sonnet
   */
  async generateUserStories(prdContent) {
    console.log(`[OpenRouter:${this.modelConfig.userStories}] Generating user stories`);
    return await this.executeTool('user-stories-generator', { 
      prdContent,
      outputFormat: 'detailed'
    });
  }

  /**
   * Generate Task List with Gemini 2.5 Flash
   */
  async generateTaskList(userStoriesContent) {
    console.log(`[OpenRouter:${this.modelConfig.taskList}] Generating task list`);
    return await this.executeTool('task-list-generator', { 
      userStoriesContent 
    });
  }

  /**
   * Generate Code with Gemini 2.5 Flash or GPT-4
   */
  async generateStarterKit(productDescription, frontend = 'react', backend = 'nodejs') {
    console.log(`[OpenRouter:${this.modelConfig.codeGeneration}] Generating code: ${frontend} + ${backend}`);
    return await this.executeTool('fullstack-starter-kit-generator', {
      productDescription,
      frontend,
      backend,
      includeAuth: true,
      includeDatabase: true
    });
  }
}

const mcpService = new MCPService();
export default mcpService;
```

---

### Step 4: Create Conversational Controller

Create `backend/controllers/conversationController.js`:

```javascript
import groqService from '../services/groqService.js';
import mcpService from '../services/mcpService.js';

// Store conversation history per session
const conversationSessions = new Map();

export const conversationController = {
  /**
   * Handle conversational chat
   */
  async chat(req, res) {
    try {
      const { message, sessionId } = req.body;

      if (!message) {
        return res.status(400).json({
          success: false,
          error: 'Message is required'
        });
      }

      // Get or create conversation history
      const session = sessionId || `session_${Date.now()}`;
      let conversationHistory = conversationSessions.get(session) || [
        groqService.getSystemPrompt()
      ];

      // Add user message
      conversationHistory.push({
        role: 'user',
        content: message
      });

      console.log(`\nüí¨ User [${session}]: ${message}`);

      // Get Groq response (may include tool calls)
      let groqResponse = await groqService.chat(conversationHistory);
      let assistantMessage = groqResponse.choices[0].message;

      // Handle tool calls
      while (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
        // Add assistant message with tool calls to history
        conversationHistory.push(assistantMessage);

        console.log(`\nüîß Groq wants to use ${assistantMessage.tool_calls.length} tool(s)`);

        // Execute each tool call
        for (const toolCall of assistantMessage.tool_calls) {
          const toolName = toolCall.function.name;
          const toolArgs = JSON.parse(toolCall.function.arguments);

          console.log(`\n‚öôÔ∏è  Executing: ${toolName}`);
          console.log(`   Arguments:`, toolArgs);

          let toolResult;

          try {
            // Route to appropriate MCP tool
            toolResult = await this.executeToolCall(toolName, toolArgs);
            console.log(`‚úÖ Tool completed successfully`);
          } catch (error) {
            console.error(`‚ùå Tool execution failed:`, error.message);
            toolResult = {
              error: error.message,
              success: false
            };
          }

          // Add tool result to conversation
          conversationHistory.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: JSON.stringify(toolResult)
          });
        }

        // Get next Groq response with tool results
        groqResponse = await groqService.chat(conversationHistory);
        assistantMessage = groqResponse.choices[0].message;
      }

      // Add final assistant message to history
      conversationHistory.push(assistantMessage);

      // Save conversation history
      conversationSessions.set(session, conversationHistory);

      console.log(`\nü§ñ Assistant: ${assistantMessage.content}\n`);

      res.json({
        success: true,
        data: {
          message: assistantMessage.content,
          sessionId: session,
          conversationLength: conversationHistory.length
        }
      });

    } catch (error) {
      console.error('Chat error:', error);
      res.status(500).json({
        success: false,
        error: error.message
      });
    }
  },

  /**
   * Stream conversational chat (real-time response)
   */
  async streamChat(req, res) {
    try {
      const { message, sessionId } = req.body;

      if (!message) {
        return res.status(400).json({
          success: false,
          error: 'Message is required'
        });
      }

      // Set up SSE
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');

      const session = sessionId || `session_${Date.now()}`;
      let conversationHistory = conversationSessions.get(session) || [
        groqService.getSystemPrompt()
      ];

      conversationHistory.push({
        role: 'user',
        content: message
      });

      // Stream Groq response
      const stream = await groqService.streamChat(conversationHistory);

      let accumulatedContent = '';
      let accumulatedToolCalls = [];

      for await (const chunk of stream) {
        const delta = chunk.choices[0]?.delta;

        if (delta?.content) {
          accumulatedContent += delta.content;
          res.write(`data: ${JSON.stringify({ 
            type: 'content', 
            content: delta.content 
          })}\n\n`);
        }

        if (delta?.tool_calls) {
          accumulatedToolCalls.push(...delta.tool_calls);
        }

        // Handle finish reason
        if (chunk.choices[0]?.finish_reason === 'tool_calls') {
          res.write(`data: ${JSON.stringify({ 
            type: 'tool_call', 
            tools: accumulatedToolCalls 
          })}\n\n`);
          
          // Execute tools and continue conversation
          // (Implementation similar to non-streaming version)
        }
      }

      conversationHistory.push({
        role: 'assistant',
        content: accumulatedContent
      });

      conversationSessions.set(session, conversationHistory);

      res.write(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
      res.end();

    } catch (error) {
      console.error('Stream error:', error);
      res.write(`data: ${JSON.stringify({ 
        type: 'error', 
        error: error.message 
      })}\n\n`);
      res.end();
    }
  },

  /**
   * Execute tool call by routing to MCP service
   */
  async executeToolCall(toolName, args) {
    switch (toolName) {
      case 'research_best_practices':
        return await mcpService.research(args.query);

      case 'generate_prd':
        return await mcpService.generatePRD(args.productDescription);

      case 'generate_user_stories':
        return await mcpService.generateUserStories(args.prdContent);

      case 'generate_task_list':
        return await mcpService.generateTaskList(args.userStoriesContent);

      case 'generate_website_code':
        return await mcpService.generateStarterKit(
          args.productDescription,
          args.frontend,
          args.backend
        );

      default:
        throw new Error(`Unknown tool: ${toolName}`);
    }
  },

  /**
   * Get conversation history
   */
  async getHistory(req, res) {
    try {
      const { sessionId } = req.params;
      
      const history = conversationSessions.get(sessionId);
      
      if (!history) {
        return res.status(404).json({
          success: false,
          error: 'Session not found'
        });
      }

      res.json({
        success: true,
        data: {
          sessionId,
          messages: history.filter(msg => msg.role !== 'system'),
          messageCount: history.length - 1
        }
      });

    } catch (error) {
      console.error('Get history error:', error);
      res.status(500).json({
        success: false,
        error: error.message
      });
    }
  },

  /**
   * Clear conversation history
   */
  async clearHistory(req, res) {
    try {
      const { sessionId } = req.params;
      
      conversationSessions.delete(sessionId);
      
      res.json({
        success: true,
        message: 'Conversation history cleared'
      });

    } catch (error) {
      console.error('Clear history error:', error);
      res.status(500).json({
        success: false,
        error: error.message
      });
    }
  }
};
```

---

### Step 5: Update Routes

Create `backend/routes/conversation.js`:

```javascript
import express from 'express';
import { conversationController } from '../controllers/conversationController.js';

const router = express.Router();

// Conversational endpoints
router.post('/chat', conversationController.chat);
router.post('/chat/stream', conversationController.streamChat);
router.get('/history/:sessionId', conversationController.getHistory);
router.delete('/history/:sessionId', conversationController.clearHistory);

export default router;
```

Update `backend/server.js`:

```javascript
import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import conversationRoutes from './routes/conversation.js';
import mcpService from './services/mcpService.js';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors({
  origin: process.env.FRONTEND_URL || 'http://localhost:3000',
  credentials: true
}));
app.use(express.json());

// Routes
app.use('/api/conversation', conversationRoutes);

// Health check
app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    mcpReady: mcpService.isReady,
    timestamp: new Date().toISOString()
  });
});

// Root endpoint
app.get('/', (req, res) => {
  res.json({
    message: 'Conversational AI Website Builder API',
    version: '2.0.0',
    features: ['Groq Conversational AI', 'OpenRouter Tool Execution', 'MCP Tools'],
    endpoints: {
      chat: 'POST /api/conversation/chat',
      streamChat: 'POST /api/conversation/chat/stream',
      history: 'GET /api/conversation/history/:sessionId',
      health: 'GET /health'
    }
  });
});

// Start server
async function startServer() {
  try {
    console.log('üåç Environment:', process.env.NODE_ENV);
    console.log('üöÄ Starting MCP Server...');
    
    await mcpService.startServer();

    app.listen(PORT, '0.0.0.0', () => {
      console.log(`\n‚úÖ Backend server running on http://localhost:${PORT}`);
      console.log(`‚úÖ MCP Server ready with OpenRouter`);
      console.log(`‚úÖ Groq conversational AI active`);
      console.log(`\nAPI Endpoints:`);
      console.log(`  POST /api/conversation/chat`);
      console.log(`  POST /api/conversation/chat/stream`);
      console.log(`  GET  /api/conversation/history/:sessionId`);
      console.log(`  GET  /health\n`);
    });
  } catch (error) {
    console.error('Failed to start server:', error);
    process.exit(1);
  }
}

// Graceful shutdown
process.on('SIGINT', () => {
  console.log('\nüõë Shutting down gracefully...');
  mcpService.stopServer();
  process.exit(0);
});

process.on('SIGTERM', () => {
  console.log('\nüõë Shutting down gracefully...');
  mcpService.stopServer();
  process.exit(0);
});

startServer();
```

---

## üíª Frontend Implementation

### Step 1: Update API Service

Create `frontend/src/services/conversationService.js`:

```javascript
import axios from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:3000/api';

class ConversationService {
  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 180000, // 3 minutes for complex operations
      headers: {
        'Content-Type': 'application/json',
      },
    });
    this.sessionId = this.getOrCreateSessionId();
  }

  getOrCreateSessionId() {
    let sessionId = localStorage.getItem('conversationSessionId');
    if (!sessionId) {
      sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      localStorage.setItem('conversationSessionId', sessionId);
    }
    return sessionId;
  }

  /**
   * Send message to conversational AI
   */
  async sendMessage(message) {
    try {
      const response = await this.client.post('/conversation/chat', {
        message,
        sessionId: this.sessionId
      });
      return response.data;
    } catch (error) {
      throw this.handleError(error);
    }
  }

  /**
   * Stream message for real-time response
   */
  async streamMessage(message, onChunk, onComplete, onError) {
    try {
      const response = await fetch(`${API_BASE_URL}/conversation/chat/stream`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message,
          sessionId: this.sessionId
        })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));
            
            if (data.type === 'content') {
              onChunk(data.content);
            } else if (data.type === 'done') {
              onComplete();
            } else if (data.type === 'error') {
              onError(data.error);
            }
          }
        }
      }
    } catch (error) {
      onError(this.handleError(error));
    }
  }

  /**
   * Get conversation history
   */
  async getHistory() {
    try {
      const response = await this.client.get(`/conversation/history/${this.sessionId}`);
      return response.data;
    } catch (error) {
      throw this.handleError(error);
    }
  }

  /**
   * Clear conversation and start fresh
   */
  async clearConversation() {
    try {
      await this.client.delete(`/conversation/history/${this.sessionId}`);
      // Create new session
      this.sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      localStorage.setItem('conversationSessionId', this.sessionId);
    } catch (error) {
      throw this.handleError(error);
    }
  }

  handleError(error) {
    if (error.response) {
      return new Error(error.response.data.error || 'Server error occurred');
    } else if (error.request) {
      return new Error('No response from server. Please check if backend is running.');
    } else {
      return new Error(error.message || 'An unexpected error occurred');
    }
  }
}

export default new ConversationService();
```

---

### Step 2: Create Chat Component

Create `frontend/src/components/ChatInterface.jsx`:

```javascript
import React, { useState, useRef, useEffect } from 'react';
import conversationService from '../services/conversationService';
import './ChatInterface.css';

function ChatInterface() {
  const [messages, setMessages] = useState([
    {
      role: 'assistant',
      content: "üëã Hi! I'm your AI website builder assistant. Tell me what kind of website you'd like to create, and I'll help bring it to life! I can research best practices, plan your project, and generate the complete code.",
      timestamp: new Date()
    }
  ]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isTyping, setIsTyping] = useState(false);
  const messagesEndRef = useRef(null);
  const inputRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSend = async () => {
    if (!input.trim() || isLoading) return;

    const userMessage = {
      role: 'user',
      content: input,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);
    setIsTyping(true);

    try {
      // Use streaming for better UX
      let assistantContent = '';
      const assistantMessage = {
        role: 'assistant',
        content: '',
        timestamp: new Date()
      };

      setMessages(prev => [...prev, assistantMessage]);

      await conversationService.streamMessage(
        input,
        // On chunk
        (chunk) => {
          assistantContent += chunk;
          setMessages(prev => {
            const newMessages = [...prev];
            newMessages[newMessages.length - 1] = {
              ...assistantMessage,
              content: assistantContent
            };
            return newMessages;
          });
        },
        // On complete
        () => {
          setIsLoading(false);
          setIsTyping(false);
          inputRef.current?.focus();
        },
        // On error
        (error) => {
          console.error('Stream error:', error);
          setMessages(prev => [...prev, {
            role: 'assistant',
            content: `‚ùå Sorry, I encountered an error: ${error.message}. Please try again.`,
            timestamp: new Date()
          }]);
          setIsLoading(false);
          setIsTyping(false);
        }
      );

    } catch (error) {
      console.error('Error:', error);
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: `‚ùå Sorry, I encountered an error: ${error.message}. Please try again.`,
        timestamp: new Date()
      }]);
      setIsLoading(false);
      setIsTyping(false);
    }
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  const handleClearChat = async () => {
    if (window.confirm('Clear conversation and start fresh?')) {
      try {
        await conversationService.clearConversation();
        setMessages([
          {
            role: 'assistant',
            content: "üëã Hi! I'm your AI website builder assistant. Tell me what kind of website you'd like to create!",
            timestamp: new Date()
          }
        ]);
      } catch (error) {
        console.error('Error clearing chat:', error);
      }
    }
  };

  const examplePrompts = [
    "Build a modern blog platform with user authentication",
    "Create an e-commerce store for selling handmade jewelry",
    "I need a task management app like Trello with real-time updates",
    "Build a portfolio website for a photographer with image galleries"
  ];

  return (
    <div className="chat-interface">
      {/* Header */}
      <div className="chat-header">
        <div className="header-content">
          <h1>ü§ñ AI Website Builder</h1>
          <p>Powered by Groq + OpenRouter + MCP</p>
        </div>
        <button className="clear-button" onClick={handleClearChat}>
          üîÑ New Chat
        </button>
      </div>

      {/* Messages */}
      <div className="chat-messages">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            <div className="message-avatar">
              {msg.role === 'user' ? 'üë§' : 'ü§ñ'}
            </div>
            <div className="message-content">
              <div className="message-text">{msg.content}</div>
              <div className="message-time">
                {msg.timestamp.toLocaleTimeString([], { 
                  hour: '2-digit', 
                  minute: '2-digit' 
                })}
              </div>
            </div>
          </div>
        ))}
        
        {isTyping && (
          <div className="message assistant">
            <div className="message-avatar">ü§ñ</div>
            <div className="message-content">
              <div className="typing-indicator">
                <span></span>
                <span></span>
                <span></span>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* Example Prompts (show only if conversation is empty) */}
      {messages.length <= 1 && (
        <div className="example-prompts">
          <p className="example-title">üí° Try these examples:</p>
          <div className="example-grid">
            {examplePrompts.map((prompt, index) => (
              <button
                key={index}
                className="example-prompt"
                onClick={() => {
                  setInput(prompt);
                  inputRef.current?.focus();
                }}
              >
                {prompt}
              </button>
            ))}
          </div>
        </div>
      )}

      {/* Input */}
      <div className="chat-input">
        <textarea
          ref={inputRef}
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={handleKeyPress}
          placeholder="Describe the website you want to build..."
          disabled={isLoading}
          rows={1}
        />
        <button 
          onClick={handleSend} 
          disabled={!input.trim() || isLoading}
          className="send-button"
        >
          {isLoading ? '‚è≥' : 'üöÄ'} Send
        </button>
      </div>
    </div>
  );
}

export default ChatInterface;
```

---

### Step 3: Create Styles

Create `frontend/src/components/ChatInterface.css`:

```css
.chat-interface {
  display: flex;
  flex-direction: column;
  height: 100vh;
  max-width: 1200px;
  margin: 0 auto;
  background: #f5f5f5;
}

.chat-header {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 20px;
  display: flex;
  justify-content: space-between;
  align-items: center;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.header-content h1 {
  margin: 0;
  font-size: 1.5rem;
}

.header-content p {
  margin: 5px 0 0 0;
  opacity: 0.9;
  font-size: 0.9rem;
}

.clear-button {
  background: rgba(255, 255, 255, 0.2);
  border: 1px solid rgba(255, 255, 255, 0.3);
  color: white;
  padding: 8px 16px;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.9rem;
  transition: all 0.2s;
}

.clear-button:hover {
  background: rgba(255, 255, 255, 0.3);
}

.chat-messages {
  flex: 1;
  overflow-y: auto;
  padding: 20px;
  background: #ffffff;
}

.message {
  display: flex;
  gap: 12px;
  margin-bottom: 20px;
  animation: slideIn 0.3s ease-out;
}

@keyframes slideIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message.user {
  flex-direction: row-reverse;
}

.message-avatar {
  width: 40px;
  height: 40px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.5rem;
  flex-shrink: 0;
  background: #f0f0f0;
}

.message.user .message-avatar {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
}

.message-content {
  max-width: 70%;
  display: flex;
  flex-direction: column;
  gap: 5px;
}

.message.user .message-content {
  align-items: flex-end;
}

.message-text {
  padding: 12px 16px;
  border-radius: 12px;
  background: #f5f5f5;
  white-space: pre-wrap;
  word-wrap: break-word;
  line-height: 1.5;
}

.message.user .message-text {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
}

.message-time {
  font-size: 0.75rem;
  color: #999;
  padding: 0 8px;
}

.typing-indicator {
  display: flex;
  gap: 4px;
  padding: 12px 16px;
  background: #f5f5f5;
  border-radius: 12px;
}

.typing-indicator span {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background: #999;
  animation: typing 1.4s infinite;
}

.typing-indicator span:nth-child(2) {
  animation-delay: 0.2s;
}

.typing-indicator span:nth-child(3) {
  animation-delay: 0.4s;
}

@keyframes typing {
  0%, 60%, 100% {
    transform: translateY(0);
  }
  30% {
    transform: translateY(-10px);
  }
}

.example-prompts {
  padding: 20px;
  background: white;
  border-top: 1px solid #e0e0e0;
}

.example-title {
  margin: 0 0 15px 0;
  font-weight: 600;
  color: #666;
}

.example-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 10px;
}

.example-prompt {
  padding: 12px 16px;
  background: #f9f9f9;
  border: 1px solid #e0e0e0;
  border-radius: 8px;
  cursor: pointer;
  text-align: left;
  font-size: 0.9rem;
  transition: all 0.2s;
}

.example-prompt:hover {
  background: #667eea;
  color: white;
  border-color: #667eea;
  transform: translateY(-2px);
}

.chat-input {
  display: flex;
  gap: 12px;
  padding: 20px;
  background: white;
  border-top: 2px solid #e0e0e0;
}

.chat-input textarea {
  flex: 1;
  padding: 12px 16px;
  border: 2px solid #e0e0e0;
  border-radius: 8px;
  font-family: inherit;
  font-size: 1rem;
  resize: none;
  min-height: 50px;
  max-height: 150px;
  transition: border-color 0.2s;
}

.chat-input textarea:focus {
  outline: none;
  border-color: #667eea;
}

.send-button {
  padding: 12px 24px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border: none;
  border-radius: 8px;
  font-size: 1rem;
  font-weight: 600;
  cursor: pointer;
  transition: transform 0.2s, box-shadow 0.2s;
  white-space: nowrap;
}

.send-button:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 6px 12px rgba(102, 126, 234, 0.4);
}

.send-button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* Scrollbar styling */
.chat-messages::-webkit-scrollbar {
  width: 8px;
}

.chat-messages::-webkit-scrollbar-track {
  background: #f1f1f1;
}

.chat-messages::-webkit-scrollbar-thumb {
  background: #888;
  border-radius: 4px;
}

.chat-messages::-webkit-scrollbar-thumb:hover {
  background: #555;
}
```

---

### Step 4: Update App.js

```javascript
import React from 'react';
import ChatInterface from './components/ChatInterface';
import './App.css';

function App() {
  return (
    <div className="App">
      <ChatInterface />
    </div>
  );
}

export default App;
```

---

## üöÄ Running the Application

### Step 1: Install Dependencies

```bash
# Backend
cd backend
npm install

# Frontend
cd ../frontend
npm install
```

### Step 2: Configure Environment

Ensure `backend/.env` has all required keys:
```env
GROQ_API_KEY=gsk_your_groq_key
OPENROUTER_API_KEY=sk-or-v1-your_openrouter_key
```

### Step 3: Start Backend

```bash
cd backend
npm start
```

Expected output:
```
üöÄ Starting MCP Server with OpenRouter...
üìä Model Configuration:
   Research: perplexity/sonar-pro
   PRD: anthropic/claude-3.5-sonnet
   User Stories: anthropic/claude-3.5-sonnet
   Task List: google/gemini-2.5-flash-preview-05-20
   Code Gen: google/gemini-2.5-flash-preview-05-20
‚úÖ MCP Server is ready!
‚úÖ Backend server running on http://localhost:3000
‚úÖ Groq conversational AI active
```

### Step 4: Start Frontend

```bash
cd frontend
npm start
```

---

## üí¨ Example Conversations

### Example 1: Simple Blog

**User:** "I want to build a blog website"

**AI:** "That's a great project! Let me help you create a modern blog platform. First, let me research the best practices for blog development..."

*[AI uses research tool with Perplexity]*

**AI:** "Based on my research, I recommend using React for the frontend because of its component-based architecture and rich ecosystem. For the backend, Node.js with Express would be perfect.

Let me create a detailed requirements document for your blog..."

*[AI uses PRD generator with Claude]*

**AI:** "I've outlined all the features your blog will need:
- User authentication and profiles
- Rich text editor for creating posts
- Comment system
- Categories and tags
- Responsive design

Now I'll generate the complete code for you..."

*[AI uses code generator with Gemini]*

**AI:** "‚ú® Your blog is ready! I've created a full-stack application with:

**Frontend:**
- Modern React with Tailwind CSS
- Rich markdown editor
- Responsive design
- User authentication UI

**Backend:**
- Node.js + Express
- JWT authentication
- MongoDB database
- RESTful API

**Why these choices?**
- React: Best for interactive, dynamic UIs
- Tailwind: Rapid styling with utility classes
- JWT: Secure, stateless authentication
- MongoDB: Flexible schema perfect for blog posts

You can find your code at: `/generated-projects/blog-platform`

Would you like me to add any specific features, like email notifications or social sharing?"

---

### Example 2: E-commerce Store

**User:** "Create an online store for selling handmade jewelry"

**AI:** "How exciting! An online store for handmade jewelry - that's a beautiful niche. Let me research the best e-commerce practices and technologies..."

*[Uses research, PRD, user stories, tasks, then code generation]*

**AI:** "I've built your complete e-commerce platform! Here's what's included:

**Features:**
- Product catalog with beautiful image galleries
- Shopping cart with persistent storage
- Secure checkout with Stripe integration
- Order management system
- Admin dashboard
- Customer reviews
- Inventory tracking

**Tech Stack:**
- React + Tailwind (stunning UI)
- Node.js + Express (robust backend)
- Stripe (secure payments)
- MongoDB (product & order data)

**Why Stripe?** It's the industry standard for payment processing, handles all security, and supports multiple payment methods.

Your store is generated at: `/generated-projects/jewelry-store`

Would you like me to add features like gift wrapping options or custom engraving requests?"

---

## üí∞ Cost Analysis

### Per Conversation (Typical Website Generation):

| Component | Model | Tokens | Cost |
|-----------|-------|--------|------|
| **Conversation** (Groq) | Llama 3.3 70B | ~5,000 | **$0.00** (Free!) |
| **Research** (OpenRouter) | Perplexity Sonar | ~5,000 | $0.02 |
| **PRD** (OpenRouter) | Claude 3.5 Sonnet | ~8,000 | $0.03 |
| **User Stories** (OpenRouter) | Claude 3.5 Sonnet | ~6,000 | $0.02 |
| **Tasks** (OpenRouter) | Gemini Flash | ~5,000 | $0.001 |
| **Code** (OpenRouter) | Gemini Flash | ~15,000 | $0.002 |
| **Total** | | **~44,000** | **~$0.073** |

### Monthly Estimates:

| Usage | Conversations | Cost (Groq) | Cost (OpenRouter) | **Total** |
|-------|---------------|-------------|-------------------|-----------|
| Light (100/mo) | Free | $0 | $7.30 | **$7.30** |
| Medium (500/mo) | Free | $0 | $36.50 | **$36.50** |
| Heavy (1000/mo) | Free | $0 | $73.00 | **$73.00** |

**Key Advantage:** Groq is completely free for conversation, you only pay OpenRouter for actual work!

---

## üéØ Benefits of This Architecture

### 1. **Best of Both Worlds**
- ‚úÖ Free, fast conversation with Groq
- ‚úÖ Specialized models for specific tasks
- ‚úÖ Natural reasoning and explanations

### 2. **Cost Optimization**
- ‚úÖ Groq: Free unlimited conversation
- ‚úÖ OpenRouter: Pay only for tool execution
- ‚úÖ Smart model selection per task

### 3. **Quality**
- ‚úÖ Claude for complex reasoning (PRD, planning)
- ‚úÖ Gemini Flash for fast code generation
- ‚úÖ Perplexity for research

### 4. **User Experience**
- ‚úÖ Natural conversation
- ‚úÖ Explains all decisions
- ‚úÖ Iterative refinement
- ‚úÖ Context-aware

---

## üêõ Troubleshooting

### Issue 1: "Groq API Key Invalid"

**Solution:**
```bash
# Verify key
echo $GROQ_API_KEY

# Get new key from https://console.groq.com/
```

### Issue 2: "Tool execution failed"

**Solution:**
- Check OpenRouter API key
- Verify OpenRouter has credits
- Check MCP server is running

### Issue 3: "Conversation not streaming"

**Solution:**
- Use `/chat/stream` endpoint
- Ensure SSE headers are set
- Check browser console for errors

---

## üéâ Summary

You now have a **fully conversational AI website builder** with:

‚úÖ **Groq** for natural conversation (FREE!)  
‚úÖ **OpenRouter** with specialized models for each tool  
‚úÖ **MCP Tools** for actual code generation  
‚úÖ **ChatGPT-like experience** with reasoning  
‚úÖ **Smart model selection** for optimal cost/quality  
‚úÖ **Real-time streaming** responses  
‚úÖ **Context-aware** multi-turn conversations  

**Total cost: ~$0.07 per website generated (OpenRouter only, Groq is free!)**

The AI explains its reasoning, asks clarifying questions, and provides a natural conversational experience while using the best models for each specific task!
